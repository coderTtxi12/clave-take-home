# Gu√≠a Completa de Setup - Restaurant Analytics

Esta gu√≠a te muestra todos los pasos para configurar y ejecutar la base de datos, migraciones y ETL.

---

## üìã Tabla de Contenidos

1. [Docker - Base de Datos PostgreSQL](#1-docker---base-de-datos-postgresql)
2. [Migraciones de Base de Datos con Alembic](#2-migraciones-de-base-de-datos-con-alembic)
3. [Funciones PostgreSQL para ETL](#3-funciones-postgresql-para-etl)
4. [ETL - Carga de Datos](#4-etl---carga-de-datos)
5. [Alembic - Gu√≠a Completa](#5-alembic---gu√≠a-completa)

---

## 1. Docker - Base de Datos PostgreSQL

### ¬øQu√© es Docker Compose?

Docker Compose permite definir y ejecutar m√∫ltiples contenedores Docker. En este proyecto, usamos Docker para ejecutar PostgreSQL sin instalarlo directamente en tu m√°quina.

### Pasos para Levantar la Base de Datos

#### Paso 1: Navegar al directorio
```bash
cd my-api
```

#### Paso 2: Iniciar PostgreSQL con Docker
```bash
# Iniciar en modo detached (en segundo plano)
docker-compose up -d
```

**¬øQu√© hace este comando?**
- Lee el archivo `docker-compose.yml`
- Descarga la imagen de PostgreSQL 15 (si no existe)
- Crea un contenedor llamado `restaurant_analytics_db`
- Expone el puerto 5433 en tu m√°quina local (mapeado desde 5432 del contenedor)
- Crea un volumen persistente para los datos

#### Paso 3: Verificar que est√° corriendo
```bash
# Ver el estado de los contenedores
docker-compose ps

# Deber√≠as ver algo como:
# NAME                      STATUS          PORTS
# restaurant_analytics_db   Up X minutes     0.0.0.0:5433->5432/tcp
```

#### Paso 4: Ver los logs (opcional)
```bash
# Ver logs en tiempo real
docker-compose logs -f postgres

# Ver √∫ltimas 50 l√≠neas
docker-compose logs --tail=50 postgres
```

### Comandos √ötiles de Docker

```bash
# Detener la base de datos (mantiene los datos)
docker-compose stop

# Iniciar de nuevo
docker-compose start

# Detener y eliminar contenedores (mantiene los datos)
docker-compose down

# Detener y eliminar contenedores Y datos (‚ö†Ô∏è CUIDADO)
docker-compose down -v

# Reiniciar el servicio
docker-compose restart postgres

# Reconstruir si cambias docker-compose.yml
docker-compose up -d --build
```

### Verificar Conexi√≥n a la Base de Datos

```bash
# Conectar con psql
psql -h localhost -p 5433 -U postgres -d restaurant_analytics

# O usando la cadena de conexi√≥n
psql postgresql://postgres:postgres@localhost:5433/restaurant_analytics
```

**Credenciales por defecto:**
- Host: `localhost`
- Port: `5433` (puerto externo, el contenedor usa 5432 internamente)
- Database: `restaurant_analytics`
- User: `postgres`
- Password: `postgres`

### Soluci√≥n de Problemas

**Error: "port 5433 already in use"**
```bash
# Encontrar qu√© proceso usa el puerto
lsof -i :5433  # Mac/Linux
netstat -ano | findstr :5433  # Windows

# Si necesitas cambiar el puerto, edita docker-compose.yml
# Cambiar "5433:5432" a otro puerto, ej: "5434:5432"
```

**Error: "Cannot connect to Docker daemon"**
```bash
# Aseg√∫rate de que Docker Desktop est√© corriendo
# En Mac: Abre Docker Desktop app
# En Linux: sudo systemctl start docker
```

---

## 2. Migraciones de Base de Datos con Alembic

### ¬øQu√© es Alembic?

**Alembic** es una herramienta de migraciones de base de datos para SQLAlchemy. Permite:
- ‚úÖ Versionado autom√°tico del esquema
- ‚úÖ Historial completo de cambios
- ‚úÖ Rollback f√°cil de migraciones
- ‚úÖ Auto-generaci√≥n desde modelos SQLAlchemy

### Prerequisitos

```bash
# Activar virtual environment
source .venv/bin/activate

# Instalar dependencias (si no lo has hecho)
pip install -r requirements.txt
```

### Aplicar Migraciones

#### Opci√≥n 1: Usar el Script Helper (Recomendado)

```bash
cd my-api

# Aplicar todas las migraciones
./run_alembic_migrations.sh upgrade head

# Ver estado actual
./run_alembic_migrations.sh current

# Ver historial
./run_alembic_migrations.sh history
```

#### Opci√≥n 2: Usar Alembic Directamente

```bash
# Activar virtual environment
source .venv/bin/activate

# Aplicar todas las migraciones
alembic upgrade head

# Ver versi√≥n actual
alembic current

# Ver historial
alembic history
```

**¬øQu√© hace `alembic upgrade head`?**
1. Lee las migraciones en `alembic/versions/`
2. Verifica qu√© migraciones ya se ejecutaron
3. Ejecuta solo las migraciones pendientes
4. Actualiza la tabla `alembic_version` con el estado

### Verificar que las Migraciones Funcionaron

```bash
# Conectar a la base de datos
psql -h localhost -p 5433 -U postgres -d restaurant_analytics

# Dentro de psql, ejecutar:
\dt                    # Lista todas las tablas
\d                     # Lista todos los objetos

# Verificar tablas principales
SELECT COUNT(*) FROM locations;
SELECT COUNT(*) FROM categories;
SELECT COUNT(*) FROM products;
SELECT COUNT(*) FROM orders;
```

### Resetear la Base de Datos (Empezar de Cero)

```bash
# ‚ö†Ô∏è CUIDADO: Esto borra TODOS los datos

# Opci√≥n 1: Usar Docker (recomendado)
docker-compose down -v
docker-compose up -d
sleep 5
alembic upgrade head

# Opci√≥n 2: Eliminar y recrear manualmente
psql -h localhost -p 5433 -U postgres -d postgres -c "DROP DATABASE IF EXISTS restaurant_analytics;"
psql -h localhost -p 5433 -U postgres -d postgres -c "CREATE DATABASE restaurant_analytics;"
alembic upgrade head
```

### Revertir Migraciones

```bash
# Revertir √∫ltima migraci√≥n
alembic downgrade -1

# Revertir hasta una versi√≥n espec√≠fica
alembic downgrade <revision_id>

# Revertir todas las migraciones
alembic downgrade base
```

---

## 3. Funciones PostgreSQL para ETL

### ¬øPor qu√© Necesitas Estas Funciones?

Los scripts ETL usan funciones PostgreSQL helper que **NO est√°n incluidas** en las migraciones de Alembic (son l√≥gica de negocio, no estructura de base de datos).

### Funciones Incluidas

1. **`get_location_id_by_source(source, source_id)`**
   - Mapea source IDs a location IDs

2. **`get_or_create_category(category_name)`**
   - Normaliza y crea categor√≠as autom√°ticamente
   - **Usado por:** `scripts/etl_utils.py`

3. **`validate_etl_data()`**
   - Valida integridad de datos despu√©s de cargar
   - **Usado por:** `scripts/load_all_data.py`

### Instalaci√≥n

#### Opci√≥n 1: Script Autom√°tico (Recomendado)

```bash
cd my-api

# Instalar funciones ETL
./install_etl_functions.sh
```

**¬øQu√© hace el script?**
1. Verifica conexi√≥n a la base de datos
2. Ejecuta `sql/etl_functions.sql`
3. Crea las 3 funciones necesarias
4. Muestra confirmaci√≥n

#### Opci√≥n 2: Manual

```bash
# Ejecutar archivo SQL directamente
psql -h localhost -p 5433 -U postgres -d restaurant_analytics -f sql/etl_functions.sql
```

### Verificar Instalaci√≥n

```bash
# Conectar a la base de datos
psql -h localhost -p 5433 -U postgres -d restaurant_analytics

# Dentro de psql:
\df get_location_id_by_source
\df get_or_create_category
\df validate_etl_data

# Probar una funci√≥n
SELECT get_or_create_category('Test Category');
```

### ‚ö†Ô∏è Importante

**DEBES instalar estas funciones ANTES de ejecutar los scripts ETL**, de lo contrario fallar√°n con:

```
ERROR: function get_or_create_category(character varying) does not exist
```

---

## 4. ETL - Carga de Datos

### ¬øQu√© es ETL?

ETL significa **Extract, Transform, Load** (Extraer, Transformar, Cargar):
- **Extract:** Lee los archivos JSON de las fuentes (Toast, DoorDash, Square)
- **Transform:** Normaliza, limpia y unifica los datos
- **Load:** Inserta los datos en PostgreSQL

### Prerequisitos

1. ‚úÖ PostgreSQL corriendo (ver secci√≥n 1)
2. ‚úÖ Migraciones de Alembic ejecutadas (ver secci√≥n 2)
3. ‚úÖ **Funciones ETL instaladas** (ver secci√≥n 3) ‚ö†Ô∏è **NUEVO**
4. ‚úÖ Archivos JSON en `../data/sources/`:
   - `toast_pos_export.json`
   - `doordash_orders.json`
   - `square/catalog.json`
   - `square/locations.json`
   - `square/orders.json`
   - `square/payments.json`

### Opci√≥n 1: Script Autom√°tico (Recomendado)

```bash
cd my-api

# Dar permisos de ejecuci√≥n (solo la primera vez)
chmod +x load_data.sh

# Cargar todos los datos
./load_data.sh

# O para borrar datos existentes antes de cargar
./load_data.sh --clear
```

**¬øQu√© hace el script?**
1. Verifica que PostgreSQL est√© corriendo
2. Verifica que las migraciones est√©n ejecutadas
3. Verifica que los archivos JSON existan
4. Instala dependencias de Python (psycopg2-binary)
5. Ejecuta el script de ETL
6. Muestra estad√≠sticas de carga

### Opci√≥n 2: Ejecutar ETL Manualmente

```bash
cd my-api/scripts

# Instalar dependencias (solo la primera vez)
pip install psycopg2-binary

# Configurar variables de entorno
export DB_HOST=localhost
export DB_PORT=5433
export DB_NAME=restaurant_analytics
export DB_USER=postgres
export DB_PASSWORD=postgres

# Cargar todos los datos
python load_all_data.py

# O borrar datos existentes primero
python load_all_data.py --clear
```

### Cargar Fuentes Individuales

```bash
cd my-api/scripts

# Solo Toast POS
python load_toast_data.py [--clear]

# Solo DoorDash
python load_doordash_data.py [--clear]

# Solo Square POS
python load_square_data.py [--clear]
```

### ¬øQu√© Datos se Cargan?

#### Toast POS (`toast_pos_export.json`)
- ‚úÖ Locations (restaurantes)
- ‚úÖ Orders (√≥rdenes)
- ‚úÖ Checks (cuentas)
- ‚úÖ Order Items (items con modifiers)
- ‚úÖ Payments (pagos)

#### DoorDash (`doordash_orders.json`)
- ‚úÖ Stores ‚Üí Locations
- ‚úÖ Orders
- ‚úÖ Order Items con options
- ‚úÖ Delivery Orders (info de entrega)
- ‚úÖ Payments

#### Square POS (`square/*.json`)
- ‚úÖ Catalog items ‚Üí Products
- ‚úÖ Locations
- ‚úÖ Orders con line items
- ‚úÖ Payments con detalles de tarjeta

### Verificar que los Datos se Cargaron

```bash
# Conectar a la base de datos
psql -h localhost -p 5433 -U postgres -d restaurant_analytics

# Dentro de psql, ejecutar:
SELECT 'orders' as table_name, COUNT(*) FROM orders
UNION ALL
SELECT 'order_items', COUNT(*) FROM order_items
UNION ALL
SELECT 'payments', COUNT(*) FROM payments
UNION ALL
SELECT 'products', COUNT(*) FROM products;

# Ver ventas por fuente
SELECT source, COUNT(*) as orders, SUM(total_amount) as revenue
FROM orders
GROUP BY source;

# Validar integridad (usa funci√≥n ETL)
SELECT * FROM validate_etl_data();
```

### Actualizar Materialized Views

Despu√©s de cargar datos, actualiza las vistas materializadas para que los reportes est√©n actualizados:

```bash
psql -h localhost -p 5433 -U postgres -d restaurant_analytics

# Dentro de psql:
SELECT refresh_all_materialized_views();

# O actualizar individualmente:
REFRESH MATERIALIZED VIEW CONCURRENTLY daily_sales_summary;
REFRESH MATERIALIZED VIEW CONCURRENTLY product_performance;
REFRESH MATERIALIZED VIEW CONCURRENTLY hourly_sales;
REFRESH MATERIALIZED VIEW CONCURRENTLY category_performance;
REFRESH MATERIALIZED VIEW CONCURRENTLY payment_method_summary;
REFRESH MATERIALIZED VIEW CONCURRENTLY location_comparison;
```

### Soluci√≥n de Problemas ETL

**Error: "ModuleNotFoundError: No module named 'psycopg2'"**
```bash
pip install psycopg2-binary
```

**Error: "connection refused"**
```bash
# Verificar que PostgreSQL est√© corriendo
docker-compose ps
docker-compose up -d
```

**Error: "relation does not exist"**
```bash
# Ejecutar migraciones primero
alembic upgrade head
```

**Error: "function get_or_create_category does not exist"**
```bash
# Instalar funciones ETL
./install_etl_functions.sh
```

**Error: "duplicate key value violates unique constraint"**
```bash
# Usar --clear para borrar datos existentes
python load_all_data.py --clear
```

---

## 5. Alembic - Gu√≠a Completa

### ¬øQu√© es Alembic?

**Alembic** es una herramienta de migraciones de base de datos para SQLAlchemy (ORM de Python). Es el equivalente a herramientas como:
- **Django Migrations** (Django)
- **Rails Migrations** (Ruby on Rails)
- **Flyway** (Java)
- **Liquibase** (Java)

### Caracter√≠sticas de Alembic

1. **Migraciones Versionadas:** Cada cambio se guarda como un archivo Python
2. **Historial de Cambios:** Rastrea qu√© migraciones se han ejecutado
3. **Rollback:** Puede revertir migraciones
4. **Auto-generaci√≥n:** Puede generar migraciones autom√°ticamente desde modelos SQLAlchemy
5. **Dependencias:** Maneja dependencias entre migraciones

### Comandos B√°sicos

```bash
# Ver versi√≥n actual
alembic current

# Aplicar todas las migraciones
alembic upgrade head

# Revertir √∫ltima migraci√≥n
alembic downgrade -1

# Ver historial
alembic history

# Crear nueva migraci√≥n
alembic revision --autogenerate -m "add_new_field"
```

### Crear Nueva Migraci√≥n

#### Paso 1: Modificar Modelos

Edita `app/models/database.py`:

```python
class Product(Base):
    # ... campos existentes ...
    is_featured = Column(Boolean, default=False)  # ‚Üê Nuevo campo
```

#### Paso 2: Generar Migraci√≥n

```bash
alembic revision --autogenerate -m "add_is_featured_to_products"
```

#### Paso 3: Revisar Archivo Generado

Revisa `alembic/versions/xxxx_add_is_featured_to_products.py` para verificar que detect√≥ el cambio.

#### Paso 4: Aplicar Migraci√≥n

```bash
alembic upgrade head
```

### Ventajas de Alembic

| Caracter√≠stica | Beneficio |
|----------------|-----------|
| **Versionado** | Historial autom√°tico de cambios |
| **Rollback** | `alembic downgrade -1` f√°cil |
| **Auto-generaci√≥n** | Detecta cambios en modelos autom√°ticamente |
| **Team-friendly** | Merge autom√°tico de migraciones |
| **Historial** | `alembic history` muestra todo |

### Ver Documentaci√≥n Completa

Para m√°s detalles, ver:
- **[ALEMBIC_GUIDE.md](./ALEMBIC_GUIDE.md)** - Gu√≠a completa de Alembic
- **[alembic/README.md](./alembic/README.md)** - Quick reference

---

## üìù Resumen de Comandos R√°pidos

### Setup Completo (Primera Vez)

```bash
# 1. Iniciar PostgreSQL
cd my-api
docker-compose up -d

# 2. Aplicar migraciones de Alembic
source .venv/bin/activate
alembic upgrade head

# 3. Instalar funciones ETL (NUEVO PASO)
./install_etl_functions.sh

# 4. Cargar datos
./load_data.sh

# 5. Verificar
psql -h localhost -p 5433 -U postgres -d restaurant_analytics
SELECT * FROM validate_etl_data();
```

### Comandos Diarios

```bash
# Iniciar base de datos
docker-compose up -d

# Ver logs
docker-compose logs -f postgres

# Conectar a la base de datos
psql -h localhost -p 5433 -U postgres -d restaurant_analytics

# Ver estado de migraciones
alembic current

# Detener base de datos
docker-compose stop
```

### Resetear Todo (Empezar de Cero)

```bash
# ‚ö†Ô∏è CUIDADO: Borra todos los datos
docker-compose down -v
docker-compose up -d
sleep 5
alembic upgrade head
./install_etl_functions.sh
./load_data.sh --clear
```

---

## üîó Recursos Adicionales

- [README.md](./README.md) - Documentaci√≥n completa del API
- [ALEMBIC_GUIDE.md](./ALEMBIC_GUIDE.md) - Gu√≠a completa de Alembic
- [sql/README.md](./sql/README.md) - Documentaci√≥n de funciones ETL
- [scripts/README.md](./scripts/README.md) - Documentaci√≥n de ETL
- [QUICK_START.md](../QUICK_START.md) - Gu√≠a r√°pida

---

## ‚ùì Preguntas Frecuentes

**P: ¬øPor qu√© usar Alembic en lugar de SQL directo?**
R: Alembic proporciona versionado autom√°tico, rollback f√°cil, historial completo y auto-generaci√≥n desde modelos. Es mejor para proyectos en equipo y cambios frecuentes.

**P: ¬øC√≥mo s√© qu√© migraciones se han ejecutado?**
R: Usa `alembic current` para ver la versi√≥n actual, o `alembic history` para ver todas las migraciones.

**P: ¬øPuedo revertir una migraci√≥n?**
R: S√≠, usa `alembic downgrade -1` para revertir la √∫ltima migraci√≥n, o `alembic downgrade <revision_id>` para una espec√≠fica.

**P: ¬øPor qu√© necesito instalar funciones ETL por separado?**
R: Las funciones ETL son l√≥gica de negocio, no estructura de base de datos. No est√°n en las migraciones de Alembic porque son independientes del esquema.

**P: ¬øQu√© pasa si ejecuto una migraci√≥n dos veces?**
R: Alembic rastrea qu√© migraciones se ejecutaron. No ejecutar√° la misma migraci√≥n dos veces autom√°ticamente.

**P: ¬øPuedo modificar las migraciones despu√©s de ejecutarlas?**
R: No es recomendable. Mejor crear una nueva migraci√≥n con los cambios adicionales.

---

**¬øNecesitas ayuda?** Revisa los logs de Docker o los mensajes de error para m√°s detalles.

